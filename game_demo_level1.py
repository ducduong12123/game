import streamlit as st
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.document_loaders import TextLoader
from langchain.prompts import PromptTemplate
from dotenv import load_dotenv
import os
import tempfile

# H√†m ƒë·ªÉ x·ª≠ l√Ω logic RAG v·ªõi Langchain

def process_query_with_langchain(api_key, file_path, query):
    os.environ["GOOGLE_API_KEY"] = api_key

    # 1. Load d·ªØ li·ªáu t·ª´ file
    loader = TextLoader(file_path, encoding='utf-8')
    documents = loader.load()
    if not documents:
        return "Xin l·ªói, m√¨nh ch∆∞a c√≥ th√¥ng tin t·ª´ file game. B·∫°n t·∫£i file l√™n ch∆∞a?"

    # 2. Split vƒÉn b·∫£n th√†nh c√°c chunks
    # TƒÉng chunk_size v√† chunk_overlap ƒë·ªÉ m·ªói chunk c√≥ nhi·ªÅu ng·ªØ c·∫£nh h∆°n,
    # gi√∫p LLM hi·ªÉu r√µ h∆°n v·ªÅ m·ªëi li√™n h·ªá gi·ªØa m√¥ t·∫£ nƒÉng l·ª±c, nhi·ªám v·ª•, kh√≥ khƒÉn v√† m·∫πo.
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=250)
    texts = text_splitter.split_documents(documents)
    if not texts:
        return "Kh√¥ng c√≥ n·ªôi dung n√†o ƒë∆∞·ª£c tr√≠ch xu·∫•t t·ª´ file. File c√≥ v·∫ª tr·ªëng."

    # 3. T·∫°o Embeddings
    try:
        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    except Exception as e:
        return f"L·ªói khi kh·ªüi t·∫°o embeddings: {e}. Ki·ªÉm tra API key v√† k·∫øt n·ªëi m·∫°ng nh√©."

    # 4. T·∫°o Vector Store
    try:
        vector_store = FAISS.from_documents(texts, embeddings)
    except Exception as e:
        return f"L·ªói khi t·∫°o vector store: {e}. C√≥ th·ªÉ do file d·ªØ li·ªáu qu√° nh·ªè ho·∫∑c c√≥ v·∫•n ƒë·ªÅ v·ªõi embeddings."

    # 5. T·∫°o Retriever
    # TƒÉng k ƒë·ªÉ l·∫•y nhi·ªÅu context h∆°n, gi√∫p tr·∫£ l·ªùi chi ti·∫øt h∆°n, ƒë·∫∑c bi·ªát khi th√¥ng tin v·ªÅ m·ªôt nhi·ªám v·ª• c√≥ th·ªÉ tr·∫£i d√†i
    retriever = vector_store.as_retriever(search_kwargs={"k": 5}) # L·∫•y top 5 chunks li√™n quan nh·∫•t

    # 6. T·∫°o LLM
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash-preview-04-17",
        temperature=1, # Gi·ªØ ·ªü m·ª©c trung b√¨nh ƒë·ªÉ v·ª´a s√°ng t·∫°o v·ª´a b√°m s√°t context
        convert_system_message_to_human=True
    )

    # --- C·∫≠p nh·∫≠t Prompt Template cho CyberBuddy ---
    prompt_template_text = """B·∫°n l√† CyberBuddy, m·ªôt ng∆∞·ªùi b·∫°n ƒë·ªìng h√†nh AI th√¢n thi·ªán, th√¥ng th√°i v√† lu√¥n s·∫µn s√†ng h·ªó tr·ª£ ng∆∞·ªùi ch∆°i trong tr√≤ ch∆°i CyberQuest.
M·ª•c ti√™u c·ªßa b·∫°n l√† gi√∫p ng∆∞·ªùi ch∆°i hi·ªÉu r√µ v·ªÅ c√°c m√†n ch∆°i, c√°c mi·ªÅn nƒÉng l·ª±c, c√°c nƒÉng l·ª±c th√†nh ph·∫ßn, v√† ƒë·∫∑c bi·ªát l√† c√°c nhi·ªám v·ª• c·ª• th·ªÉ.
Khi ng∆∞·ªùi ch∆°i h·ªèi v·ªÅ m·ªôt nhi·ªám v·ª•, m·ªôt kh√≥ khƒÉn, ho·∫∑c c√°ch ƒë·ªÉ v∆∞·ª£t qua m·ªôt th·ª≠ th√°ch:
1.  H√£y d·ª±a v√†o "Th√¥ng tin tr√≤ ch∆°i" ƒë∆∞·ª£c cung c·∫•p ƒë·ªÉ t√¨m ki·∫øm th√¥ng tin li√™n quan nh·∫•t.
2.  Gi·∫£i th√≠ch r√µ r√†ng m·ª•c ti√™u c·ªßa nhi·ªám v·ª• ho·∫∑c nƒÉng l·ª±c ƒë√≥.
3.  M√¥ t·∫£ chi ti·∫øt c√°ch th·ª©c th·ª±c hi·ªán nhi·ªám v·ª• (Ph∆∞∆°ng th·ª©c).
4.  N·∫øu trong "Th√¥ng tin tr√≤ ch∆°i" c√≥ m√¥ t·∫£ v·ªÅ "Kh√≥ khƒÉn th∆∞·ªùng g·∫∑p" ho·∫∑c "M·∫πo v∆∞·ª£t qua" cho nhi·ªám v·ª• ƒë√≥, h√£y tr√¨nh b√†y th·∫≠t chi ti·∫øt v√† d·ªÖ hi·ªÉu c√°c ƒëi·ªÉm n√†y ƒë·ªÉ gi√∫p ng∆∞·ªùi ch∆°i.
5.  N·∫øu ng∆∞·ªùi ch∆°i h·ªèi chung chung v·ªÅ m·ªôt m√†n ch∆°i ho·∫∑c m·ªôt nƒÉng l·ª±c, h√£y t√≥m t·∫Øt c√°c th√¥ng tin ch√≠nh.
6.  Lu√¥n s·ª≠ d·ª•ng gi·ªçng ƒëi·ªáu kh√≠ch l·ªá, t√≠ch c·ª±c v√† nh∆∞ m·ªôt ng∆∞·ªùi b·∫°n ƒëang th·ª±c s·ª± mu·ªën gi√∫p ƒë·ª°.
7.  N·∫øu kh√¥ng t√¨m th·∫•y th√¥ng tin ch√≠nh x√°c cho c√¢u h·ªèi, h√£y th√†nh th·∫≠t n√≥i r·∫±ng b·∫°n ch∆∞a c√≥ th√¥ng tin ƒë√≥ cho ph·∫ßn c·ª• th·ªÉ n√†y v√† g·ª£i √Ω ng∆∞·ªùi ch∆°i h·ªèi v·ªÅ m·ªôt kh√≠a c·∫°nh kh√°c ho·∫∑c ki·ªÉm tra l·∫°i t√™n nhi·ªám v·ª•. Tuy·ªát ƒë·ªëi kh√¥ng b·ªãa ƒë·∫∑t th√¥ng tin.
8.  Ng√¥n ng·ªØ ng∆∞·ªùi ch∆°i s·ª≠ d·ª•ng l√† ng√¥n ng·ªØ g√¨ h√£y s·ª≠ d·ª•ng ng√¥n ng·ªØ ƒë√≥ ƒë·ªÉ tr·∫£ l·ªùi, ng√¥n ng·ªØ c√≥ th·ªÉ thay ƒë·ªïi n·∫øu ng∆∞·ªùi ch∆°i mu·ªën chuy·ªÉn ƒë·ªïi ng√¥n ng·ªØ

Th√¥ng tin tr√≤ ch∆°i:
{context}

C√¢u h·ªèi t·ª´ ng∆∞·ªùi ch∆°i: {question}

CyberBuddy tr·∫£ l·ªùi chi ti·∫øt v√† th√¢n thi·ªán:"""

    CYBERBUDDY_PROMPT = PromptTemplate(
        template=prompt_template_text, input_variables=["context", "question"]
    )
    # --- K·∫øt th√∫c c·∫≠p nh·∫≠t Prompt ---

    # 7. T·∫°o RetrievalQA Chain
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff", # "stuff" ph√π h·ª£p khi context ƒë∆∞·ª£c k·ª≥ v·ªçng v·ª´a ƒë·ªß trong m·ªôt prompt
        retriever=retriever,
        return_source_documents=False, # ƒê·ªÉ c√¢u tr·∫£ l·ªùi g·ªçn g√†ng h∆°n cho ng∆∞·ªùi d√πng
        chain_type_kwargs={"prompt": CYBERBUDDY_PROMPT}
    )

    # 8. Th·ª±c hi·ªán query v√† l·∫•y k·∫øt qu·∫£
    try:
        result = qa_chain.invoke({"query": query})
        response_text = result['result']

        # Ki·ªÉm tra n·∫øu c√¢u tr·∫£ l·ªùi qu√° ng·∫Øn ho·∫∑c c√≥ v·∫ª kh√¥ng h·ªØu √≠ch
        if not response_text or len(response_text.split()) < 15: # N·∫øu √≠t h∆°n 15 t·ª´
            # B·∫°n c√≥ th·ªÉ th√™m logic th·ª≠ l·∫°i v·ªõi prompt kh√°c ·ªü ƒë√¢y n·∫øu mu·ªën
            return "B·∫°n ∆°i, m√¨nh t√¨m th·∫•y m·ªôt √≠t th√¥ng tin nh∆∞ng c√≥ v·∫ª ch∆∞a ƒë·ªß chi ti·∫øt cho c√¢u h·ªèi ƒë√≥. B·∫°n c√≥ th·ªÉ h·ªèi c·ª• th·ªÉ h∆°n v·ªÅ t√™n nhi·ªám v·ª• ho·∫∑c m·ªôt ph·∫ßn n√†o ƒë√≥ trong m√†n ch∆°i ƒë∆∞·ª£c kh√¥ng? Ho·∫∑c c√≥ th·ªÉ th√¥ng tin chi ti·∫øt v·ªÅ ph·∫ßn n√†y ch∆∞a ƒë∆∞·ª£c c·∫≠p nh·∫≠t ƒë·∫ßy ƒë·ªß cho m√¨nh."
        return response_text
    except Exception as e:
        return f"·ªêi, c√≥ l·ªói x·∫£y ra khi m√¨nh ƒëang suy nghƒ© ƒë·ªÉ gi√∫p b·∫°n: {e}"

# --- Giao di·ªán Streamlit (C·∫≠p nh·∫≠t th√¥ng ƒëi·ªáp cho th√¢n thi·ªán h∆°n) ---
st.set_page_config(page_title="CyberQuest Companion", layout="wide")
st.title("üéÆ CyberQuest Companion Bot ü§ñ")
st.markdown("M√¨nh l√† CyberBuddy, ng∆∞·ªùi b·∫°n ƒë·ªìng h√†nh c·ªßa b·∫°n trong CyberQuest! H√£y h·ªèi m√¨nh b·∫•t c·ª© ƒëi·ªÅu g√¨ v·ªÅ c√°c m√†n ch∆°i, nhi·ªám v·ª•, ho·∫∑c n·∫øu b·∫°n g·∫∑p kh√≥ khƒÉn nh√©.")

load_dotenv()
default_api_key = os.getenv("GOOGLE_API_KEY", "")

with st.sidebar:
    st.header("C·∫•u h√¨nh")
    google_api_key = st.text_input("Nh·∫≠p Google API Key c·ªßa b·∫°n:", type="password", value=default_api_key)
    uploaded_file = st.file_uploader("T·∫£i l√™n file n·ªôi dung game CyberQuest (.txt):", type=["txt"])
    st.markdown("---")
    st.markdown("""
    **Ch√†o b·∫°n! M√¨nh l√† CyberBuddy!**
    1.  Tr∆∞·ªõc ti√™n, b·∫°n h√£y gi√∫p m√¨nh t·∫£i l√™n file `.txt` ch·ª©a to√†n b·ªô th√¥ng tin v·ªÅ tr√≤ ch∆°i CyberQuest nh√© (ch√≠nh l√† file b·∫°n v·ª´a xem ƒë√≥!).
    2.  Sau khi t·∫£i l√™n, m√¨nh s·∫Ω ƒë·ªçc v√† ghi nh·ªõ t·∫•t c·∫£.
    3.  R·ªìi b·∫°n c·ª© t·ª± nhi√™n h·ªèi m√¨nh v·ªÅ c√°c m√†n ch∆°i, nhi·ªám v·ª• c·ª• th·ªÉ, ho·∫∑c n·∫øu b·∫°n ƒëang kh√¥ng bi·∫øt l√†m sao ƒë·ªÉ v∆∞·ª£t qua m·ªôt th·ª≠ th√°ch n√†o ƒë√≥ nha! M√¨nh ·ªü ƒë√¢y ƒë·ªÉ gi√∫p b·∫°n!
    """)

# Kh·ªüi t·∫°o l·ªãch s·ª≠ chat v·ªõi tin nh·∫Øn ch√†o m·ª´ng t·ª´ CyberBuddy
if 'messages' not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "Ch√†o m·ª´ng ƒë·∫øn v·ªõi CyberQuest! M√¨nh l√† CyberBuddy, s·∫µn s√†ng h·ªó tr·ª£ b·∫°n. H√£y t·∫£i file n·ªôi dung game l√™n ƒë·ªÉ m√¨nh c√≥ th·ªÉ gi√∫p b·∫°n t·ªët nh·∫•t nh√©!"}]

# Hi·ªÉn th·ªã c√°c tin nh·∫Øn ƒë√£ c√≥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Nh·∫≠n input t·ª´ ng∆∞·ªùi d√πng
user_query = st.chat_input("B·∫°n mu·ªën h·ªèi CyberBuddy ƒëi·ªÅu g√¨ v·ªÅ game CyberQuest?")

if user_query:
    # Th√™m tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠ chat
    st.session_state.messages.append({"role": "user", "content": user_query})
    with st.chat_message("user"):
        st.markdown(user_query)

    # Ki·ªÉm tra ƒëi·ªÅu ki·ªán tr∆∞·ªõc khi x·ª≠ l√Ω
    if not google_api_key:
        st.error("B·∫°n ∆°i, m√¨nh c·∫ßn Google API Key ƒë·ªÉ ho·∫°t ƒë·ªông. Nh·∫≠p ·ªü thanh b√™n gi√∫p m√¨nh nha!")
        st.session_state.messages.append({"role": "assistant", "content": "L·ªói: Vui l√≤ng nh·∫≠p Google API Key ƒë·ªÉ CyberBuddy c√≥ th·ªÉ suy nghƒ©."})
    elif uploaded_file is None:
        st.error("ƒê·ªÉ m√¨nh gi√∫p ƒë∆∞·ª£c b·∫°n, h√£y t·∫£i file n·ªôi dung game CyberQuest (.txt) l√™n ·ªü thanh b√™n nh√©!")
        st.session_state.messages.append({"role": "assistant", "content": "L·ªói: CyberBuddy c·∫ßn file d·ªØ li·ªáu game ƒë·ªÉ h·ªó tr·ª£ b·∫°n."})
    else:
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            message_placeholder.markdown("CyberBuddy ƒëang t√¨m ki·∫øm th√¥ng tin v√† suy nghƒ©...")
            # L∆∞u file t·∫£i l√™n v√†o m·ªôt file t·∫°m ƒë·ªÉ Langchain c√≥ th·ªÉ ƒë·ªçc
            with tempfile.NamedTemporaryFile(delete=False, suffix=".txt", mode="wb") as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_file_path = tmp_file.name
            try:
                # G·ªçi h√†m RAG ƒë·ªÉ l·∫•y c√¢u tr·∫£ l·ªùi
                answer = process_query_with_langchain(google_api_key, tmp_file_path, user_query)
                message_placeholder.markdown(answer)
                st.session_state.messages.append({"role": "assistant", "content": answer})
            except Exception as e:
                error_message = f"·ªêi, c√≥ l·ªói k·ªπ thu·∫≠t m·∫•t r·ªìi: {e}. B·∫°n th·ª≠ l·∫°i sau nh√©!"
                message_placeholder.error(error_message)
                st.session_state.messages.append({"role": "assistant", "content": error_message})
            finally:
                # X√≥a file t·∫°m sau khi s·ª≠ d·ª•ng
                if 'tmp_file_path' in locals() and os.path.exists(tmp_file_path):
                    os.remove(tmp_file_path)
